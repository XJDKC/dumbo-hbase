[input]
# hdfs input path, if you have more write more lines, key is useless
input=/hbase/pctest1
input=/hbase/pctest2

[env]
# hbase environment. For local test, just comment them.
hadoop=/usr/local/hadoop-2.4.1/
hadooplib=/usr/local/hadoop-2.4.1/share/hadoop/tools/lib/

[main]
# your main function
main_file=mr.py

# hdfs output path
output=/user/hadoop/pc/output

# hdfs output format(text, sequencefile), no need for hbase.
outputformat=text

overwrite=yes
nummaptasks=1
numreducetasks=0

# hbase as input, output, yes or no
hbase_input=yes
hbase_output=yes

# memory limit for one task
memlimit=2048000000

[hbase]
input=pctest
output=test
hbase.zookeeper.quorum=localhost

# only these columns are needed for input
hbase.mapred.tablecolumns=f:domain,f:html

# only these columnfamilies are needed for output
#columnfamilies=d,f

[dependence]
# mapreduce dependencies
files=comp_date_cluster.cfg

[libegg]
libegg=1.egg
libegg=2.egg
